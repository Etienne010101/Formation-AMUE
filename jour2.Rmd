---
title: "Initiation au big data"
author: AMUE et datactivi.st
ratio: 16x10
output:
  rmdshower::shower_presentation:
    self_contained: false
    katex: true
    theme: ribbon
    incremental: true
    css: presentations.css
---

## Introduction au big data


<p></p>
<p></p><p></p><p>
[Samuel Goëta](mailto:samuel@datactivi.st) et [Joël Gombin](mailto:joel@datactivi.st)
</p>
<p>
Retrouvez les matériaux sur https://github.com/datactivist/formation_marseille 
</p>



# Objectifs de la journée

- Comprendre ce qu'est la data science
- Comprendre les fondements de la modélisation et du machine learning
- Appréhender l'écosystème matériel et logiciel de la data science

# Retour sur l'open data

# Promesses et limites de la mise en données du monde

# Qu'est-ce que la data science ?

## Au commencement était la statistique

- une vieille science (18e siècle), pour aider les États (_Statistik_) mais aussi des entreprises privées (au départ, les assureurs => actuariat)
- fondée sur les probabilités
- faite par des mathématiciens
- forte dimension théorique

## Au commencement était la statistique

<iframe src="http://giphy.com/embed/9ADoZQgs0tyww" width="100%" height="450" frameBorder="0" class="giphy-embed" allowFullScreen></iframe><p><a href="http://giphy.com/gifs/obama-awesome-statistics-9ADoZQgs0tyww">via GIPHY</a></p>

## Au commencement était la statistique

> I keep saying the sexy job in the next ten years will be statisticians. People think I’m joking, but who would’ve guessed that computer engineers would’ve been the sexy job of the 1990s?

Hal Varian (Chief economist, Google), The McKinsey Quarterly, January 2009

## Data science is the new statistics?

> “I think data-scientist is a sexed up term for a statistician”

[Nate Silver](http://www.statisticsviews.com/details/feature/5133141/Nate-Silver-What-I-need-from-statisticians.html)

## Data science is the new statistics?

[![hauteur](./img/data-science-venn-diagram.png)](https://www.datanami.com/2016/01/14/as-data-science-evolves-its-taking-statistics-with-it/)

## Le rôle de l'informatique

- statistique classique : les problèmes doivent pouvoir être résolus de manière analytique (d'où le succès du fréquentisme)
- le développement de la puissance de calcul permet de résoudre des problèmes statistiques par la simulation ([MCMC](https://fr.wikipedia.org/wiki/M%C3%A9thode_de_Monte-Carlo_par_cha%C3%AEnes_de_Markov))

## Développement de la puissance de calcul

[![hauteur](./img/moore.png)](http://visual.ly/infographic-about-computers)

## Développement de la capacité de stockage

[![hauteur](./img/altavista.png)](https://twitter.com/alicemazzy/status/655306196128280576?ref_src=twsrc%5Etfw)

## Développement de la capacité de stockage

[![largeur](./img/amazon.png)](https://aws.amazon.com/blogs/aws/aws-snowmobile-move-exabytes-of-data-to-the-cloud-in-weeks/)

[![largeur](./img/amazon2.jpg)](https://aws.amazon.com/blogs/aws/aws-snowmobile-move-exabytes-of-data-to-the-cloud-in-weeks/)

## La simulation, méthode reine d'estimation statistique 

Monte Carlo Markov Chain (MCMC) : papier de Metropolis et Ulam (1949)

http://chifeng.scripts.mit.edu/stuff/mcmc-demo/#HamiltonianMC,banana



# Analyse, modélisation, machine learning

## Que fait-on une fois qu'on a des données ?

- Exploratory Data Analysis (Tukey, 1977) : pas d'hypothèse préalable à tester, plutôt pour générer des hypothèses. Rôle de la datavisualisation 
- test d'hypothèse

## Que fait-on une fois qu'on a des données ?

![hauteur](./img/test.png)

## Que fait-on une fois qu'on a des données ?

- Exploratory Data Analysis (Tukey, 1977) : pas d'hypothèse préalable à tester, plutôt pour générer des hypothèses. Rôle de la datavisualisation 
- test d'hypothèse
- **modèle**

## Pourquoi modéliser ?

![largeur](./img/Hibbs.jpg)

## Pourquoi modéliser ?

- pour analyser et expliquer
- pour prédire

## Modéliser pour analyser

- un modèle réduit de la réalité
- isoler le rôle de chaque variable
- raisonner "toutes choses égales par ailleurs" (_ceteris paribus_)

## Modéliser pour analyser

Modéliser, c’est mettre en relation une *variable expliquée*
(dépendante / prédite) et une ou plusieurs *variables explicatives*
(indépendantes / prédicteurs).

*Y* = *f*(*X~1~*, *X~2~*, *X~3~*, ..., *X~n~*)

L’estimation du modèle consiste à estimer la valeur des paramètres
(ou coefficients).

*Y* = *α* + *β~1~X~1~* + *β~2~X~2~* + *β~3~X~3~* + · · · + *β~n~X~n~* + *ε*

## Modéliser pour analyser

Implique de faire des hypothèses sur la spécification du modèle :

- variables explicatives
- distribution des erreurs

## Les distributions

- distribution théorique (ex : distribution normale)
- distribution empirique

http://shiny.stat.calpoly.edu/Prob_View/

## All models are wrong, some are useful

> Since all models are wrong the scientist cannot obtain a "correct" one by excessive elaboration. On the contrary following William of Occam he should seek an economical description of natural phenomena. 

[George Box](https://dx.doi.org/10.1080%2F01621459.1976.10480949)

## All models are wrong, some are useful

![largeur](./img/ockham.jpg)

## Estimation d'un modèle

Dans le cas d'un modèle linéaire => méthode des moindres carrés ordinaires (MCO/OLS)

http://setosa.io/ev/ordinary-least-squares-regression/

## Attention !

- Les modèles de régression linéaire supposent que les relations
sont *linéaires* et *additives*.
- Les *résidus* sont supposés être *normalement distribués*.
- Les coefficients ne sont *pas standardisés* (on ne peut les
comparer entre eux).
- Les coefficients s’interprètent *relativement à l’unité de la variable dépendante*.

## Attention !

- Les coefficients estiment l’effet d’une variable indépendante
sur la variable dépendante *toutes choses égales par ailleurs*,
c’est-à-dire en neutralisant l’effet des autres variables.
- La qualité globale du modèle peut être quantifié au travers du
$R^2$, qui représente la part de variance (de la variable
dépendante) expliquée.
- Pour les variables indépendantes catégoriques, on estime un
coefficient par modalité, à l’exception de la première
(baseline).

## Modèles statistiques

Compromis entre intelligibilité et fidélité aux données

## Underfitting et overfitting

![largeur](./img/underfit.png)

## Underfitting et overfitting

- différencier données d'apprentissage et données de test 
- n'utiliser les données de confirmation (test) qu'une fois 

## Extrapolation

[![largeur](./img/sinus.png)](http://r4ds.had.co.nz/model-basics.html)


## Et le machine learning alors ?

- Fondamentalement, modélisation et machine learning ne sont pas différents, du point de vue d'un statisticien : modéliser un $Y$ en fonction d'un vecteur de $X_i$
- une des différences principales toutefois : veut-on prévoir ou comprendre/analyser ?
- et donc : peut-on, veut-on interpréter les coefficients ?
- en pratique : machine learning porte sur des données plus complexes que la modélisation traditionnelle
- souvent beaucoup de valeurs manquantes 

## Et le machine learning alors ?

![largeur](./img/ratings.png)

## Concepts de machine learning

- Apprentissage supervisé vs non supervisé 
- Apprentissage supervisé : il faut des données déjà classées/étalonnées. Souvent à la main !

## Apprentissage supervisé 

[![largeur](./img/captcha.jpg)](https://fakecaptcha.com)

## Apprentissage supervisé

[![hauteur](./img/opensolarmap.png)](https://cquest.hackpad.com/OpenSolarMap-9oMiYswLksF)

## Apprentissage supervisé

[![largeur](./img/inbox.png)](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/36955.pdf)

## Apprentissage non supervisé 

- problème majeur : réduction de la dimensionnalité
- jeux de données à très hautes dimensionnalité : impossible à explorer visuellement. Comment simplifier l'information et la résumer ?

![largeur](./img/house.png)

## Apprentissage non supervisé 

https://gallery.shinyapps.io/LDAelife/

# Quelques algorithmes notoires

## Apprentissage supervisé

- la régression (linéaire, logistique, LOESS...), éventuellement régularisée (Ridge, LASSO...)
- les arbres de décision
- Naive Bayes (indépendance des attributs)
- Réseau bayésien (graphe de corrélation entre variables, inclut des _priors_)
- réseau de neurones (perceptron, back-propagation, Hopfield network...)
- Deep learning
- Random forest, Boosting, Gradient Boosting
- Support vector machine

## Apprentissage non supervisé

- clustering : k-means, k-medians, CAH... 
- réduction de la dimensionnalité : ACP, analyse géométrique des données, MDS, LDA topic clustering...
- analyses de réseau

## Le cas du deep learning

Comment apprendre à un ordinateur à lire ?

![largeur](./img/digits.png)

## Le cas du deep learning

![hauteur](./img/mnist_100_digits.png)

## Le cas du deep learning

Un perceptron

![largeur](./img/perceptron.png)

## Le cas du deep learning

![largeur](./img/smallnetwork.png)

## Le cas du deep learning

Une sigmoïde

![largeur](./img/sigmoid.png)

## Le cas du deep learning

![largeur](./img/layers.png)

## Le cas du deep learning

![hauteur](./img/number.gif)

## Le cas du deep learning

![hauteur](./img/hiddenlayer.png)

## Le cas du deep learning

Le gradient descent

![hauteur](./img/valley_with_ball.png)

+ backpropagation

## Le cas du deep learning

http://chifeng.scripts.mit.edu/stuff/mcmc-demo/#HamiltonianMC,squiggle

## Le cas du deep learning

http://playground.tensorflow.org/

## Le cas du deep learning

Décompose un problème complexe (reconnaissance faciale, par exemple) en un grand nombre de problèmes simples => beaucoup de couches cachées => **abstraction**

## Les points auxquels prêter attention

- feature selection
- régularisation
- qualité du critère d'optimisation
- qualité de la distance/métrique retenue
- qualité des données d'input (GIGO)
- ...


# L'écosystème de la data science

## Bases de données

Marché de ~ 25 milliards de $

Oracle, Microsoft... MySQL, PostgreSQL, SQLite...

DB orientées colonnes : MonetDB...

NoSQL : MangoBD, CouchDB, BigTable (Google), Neo4j, Redis, 

## Bases de données distribuées

Hadoop / Cloudera 

=> MapReduce et HDFS

## Hadoop

[![](./img/bigdata.jpeg)](https://www.chrisstucchio.com/blog/2013/hadoop_hatred.html)

Voir aussi http://ismydatabig.com/

## Hadoop / MapReduce

Permet une réelle scalabilité (ajoutons des nœuds), MAIS contraint fortement les algorithmes pouvant être utilisés, qui doivent être parallélisables. Ex : ACP => c'est compliqué

## Spark

Principe similaire à Hadoop, mais travaille en mémoire vive de manière non séquentielle

De 10 à 100x plus rapide que Hadoop

## Langages

- Java
- Python
- R
- Scala
- Julia
- SQL
- ...

## Une carte interactive 

http://xyz.insightdataengineering.com/blog/pipeline_map.html

